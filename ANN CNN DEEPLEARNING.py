# -*- coding: utf-8 -*-
"""Untitled171.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u01njxKd6eYzMwxfWwcupLuv3CyY3FqC
"""

pip install tensorflow==2.13.

import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))

import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))



import tensorflow as tf
print(tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

dataset=pd.read_csv('/content/Churn_Modelling.csv')

dataset.head()

x=dataset.iloc[:,3:13]
y=dataset['Exited']

x.head()

y.head()

geography=pd.get_dummies(x['Geography'],drop_first=True)
gender=pd.get_dummies(x['Gender'],drop_first=True)

x

x=pd.concat([x,geography,gender],axis=1)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

from sklearn.preprocessing import StandardScaler
sc= StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.transform(x_test)

x_train

x_test

x_train.shape

#creating ANN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LeakyReLU,ReLU,PReLU,ELU
from tensorflow.keras.layers import Dropout

#intializing ANN
classiffier=Sequential()

from keras.api._v2.keras import activations
#intializing ANN
classiffier.add(Dense(units=11, activation='relu'))

# adding first hidden layer
classiffier.add(Dense(units=7, activation='relu'))

from keras.src.backend import dropout
# adding second hidden layer
classiffier.add(Dense(units=6, activation='relu'))
classiffier.add(Dropout(0.3))

#adding output layer
classiffier.add(Dense(units=1, activation='sigmoid'))

from tensorflow._api.v2.config import optimizer
classiffier.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])

import tensorflow
opt=tensorflow.keras.optimizers.Adam(learning_rate=0.01)

import tensorflow as tf

early_stopping=tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0.0001,
    patience=0,
    verbose=1,
    mode="auto",
    baseline=None,
    restore_best_weights=False,
    start_from_epoch=0,
)

model_history=classiffier.fit(x_train,y_train,validation_split=0.33,batch_size=10,epochs=1000,callbacks=early_stopping)

model_history.history.keys()

#summarizing history for accuracy
plt.plot(model_history.history['accuracy'])

plt.plot(model_history.history['val_accuracy'])
plt.title("model accuracy")
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'],loc='upper left')

plt.plot(model_history.history['loss'])

plt.plot(model_history.history['val_loss'])
plt.title("model loss")
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'],loc='upper left')

y_pred=classiffier.predict(x_test)
y_pred=(y_pred>=0.5)

from sklearn.metrics import confusion_matrix

cm=confusion_matrix(y_test,y_pred)

cm

from sklearn.metrics import accuracy_score

score=accuracy_score(y_pred,y_test)

score

classiffier.get_weights()

#CNN implementation

import tensorflow as tf
from tensorflow.keras import datasets,layers,models
import matplotlib.pyplot as plt

#download and prepare cifar10 dataset
(train_images,train_labels),(test_images,test_labels)=datasets.cifar10.load_data()

#normalizing pixel values between 0 and 1
train_images,test_images=train_images/255.0,test_images/255.0

#verift the data
class_names=['airplane','automobile','bird','cat','deer',
             'dog','frog','horse','ship','truck']
plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i])
  plt.xlabel(class_names[train_labels[i][0]])
plt.show()

model=models.Sequential()
model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3),activation='relu'))

model.summary()

#Add dense layer on top
model.add(layers.Flatten())
model.add(layers.Dense(64,activation='relu'))
model.add(layers.Dense(10))

model.summary()

import tensorflow as tf

model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history=model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels))

plt.plot(history.history['accuracy'],label='accuracy')
plt.plot(history.history['val_accuracy'],label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5,1])
plt.legend(loc='lower right')
test_loss,test_acc=model.evaluate(test_images,test_labels,verbose=2)
print(test_acc)

test_loss,test_acc=model.evaluate(test_images,test_labels,verbose=2)
print(test_acc)

